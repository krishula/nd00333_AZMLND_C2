## Script for the project 2 screencast:

  - First screen shows all the experiments that are active at the moment. It includes the auto ml run that we created in task 1 from the documentation and the two runs for azure ml sdk pipeline (task 2); one for the train data and the other for the pipeline-rest-endpoint.
  - Then we select the experiment “auto-ml-project2” and see that the run has been completed. Among a list of models, we can see the best model turned out to be “Voting Ensemble” with an accuracy of about 92%. We had selected the best model for deployment and enabled "Authentication" while deploying the model using Azure Container Instance (ACI). In the screencast, we can see that it has been successfully deployed. The state of deployment is healthy and we have successfully generated the swagger URI and Applications Insights are enabled. The executed code in logs.py enables Application Insights. "Application Insights enabled" is disabled before executing logs.py.
  - After that we move to “Pipelines” and look at the “Run 1” for the azure ml sdk pipeline run. It’s been successfully completed. We had configured automl pipeline and PipelineData for the metrics output and the best model output of the pipeline. 
  - We have the REST url in our workspace in the portal. Then we build an HTTP POST request to the endpoint, specifying our authentication header. Added a JSON payload object with the experiment name and the batch size parameter. The process_count_per_node is passed through to ParallelRunStep since we defined it as a PipelineParameter object in the step configuration. We publish the pipeline endpoint and request post after. 
  - If we check the run status of the experiment “pipeline-rest-endpoint” in the screencast, it's also completed. The experiment "pipeline-rest-endpoint" was created when we published the pipeline endpoint.
  - At the end, we go back to “Pipelines” and select the tab “Pipeline Endpoints”, where we can see the “Published pipeline overview” and its last run status being “Finished”.

Thank you!
